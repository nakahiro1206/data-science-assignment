{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "talent_list = [\n",
    "    {\n",
    "        \"name\": \"アンジュ・カトリーナ\",\n",
    "        \"path\": \"../data_collection/training/chat-ange.mp3\",\n",
    "        \"color\": \"#C83C35\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"リゼ・ヘルエスタ\",\n",
    "        \"path\": \"../data_collection/training/chat-lize.mp3\",\n",
    "        \"color\": \"#42FFFF\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"戌亥とこ\",\n",
    "        \"path\": \"../data_collection/training/chat-toko.mp3\",\n",
    "        \"color\": \"#92F3A4\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle code (https://www.kaggle.com/code/anmour/svm-using-mfcc-features)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import skew\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Generate mfcc features with mean and standard deviation\n",
    "def get_mfcc(segment, SAMPLE_RATE):\n",
    "    data = segment\n",
    "    # try:\n",
    "\n",
    "    ft1 = librosa.feature.mfcc(y = data, sr = SAMPLE_RATE, n_mfcc=30)\n",
    "    ft2 = librosa.feature.zero_crossing_rate(y = data)[0]\n",
    "    ft3 = librosa.feature.spectral_rolloff(y = data, sr = SAMPLE_RATE)[0]\n",
    "    ft4 = librosa.feature.spectral_centroid(y = data, sr = SAMPLE_RATE)[0]\n",
    "    ft5 = librosa.feature.spectral_contrast(y = data, sr = SAMPLE_RATE)[0]\n",
    "    ft6 = librosa.feature.spectral_bandwidth(y = data, sr = SAMPLE_RATE)[0]\n",
    "    ft1_trunc = np.hstack((np.mean(ft1, axis=1), np.std(ft1, axis=1), skew(ft1, axis = 1), np.max(ft1, axis = 1), np.median(ft1, axis = 1), np.min(ft1, axis = 1)))\n",
    "    ft2_trunc = np.hstack((np.mean(ft2), np.std(ft2), skew(ft2), np.max(ft2), np.median(ft2), np.min(ft2)))\n",
    "    ft3_trunc = np.hstack((np.mean(ft3), np.std(ft3), skew(ft3), np.max(ft3), np.median(ft3), np.min(ft3)))\n",
    "    ft4_trunc = np.hstack((np.mean(ft4), np.std(ft4), skew(ft4), np.max(ft4), np.median(ft4), np.min(ft4)))\n",
    "    ft5_trunc = np.hstack((np.mean(ft5), np.std(ft5), skew(ft5), np.max(ft5), np.median(ft5), np.min(ft5)))\n",
    "    ft6_trunc = np.hstack((np.mean(ft6), np.std(ft6), skew(ft6), np.max(ft6), np.median(ft6), np.max(ft6)))\n",
    "    return pd.Series(np.hstack((ft1_trunc, ft2_trunc, ft3_trunc, ft4_trunc, ft5_trunc, ft6_trunc)))\n",
    "    \n",
    "    # except:\n",
    "    #     print('bad file')\n",
    "    #     return pd.Series([0]*210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n9/f02ch2416_7cp5wybnwwhh7r0000gn/T/ipykernel_7385/1113529483.py:34: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  ft1_trunc = np.hstack((np.mean(ft1, axis=1), np.std(ft1, axis=1), skew(ft1, axis = 1), np.max(ft1, axis = 1), np.median(ft1, axis = 1), np.min(ft1, axis = 1)))\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "sample_rate = 22050\n",
    "segment_duration = 2  # seconds\n",
    "mfccs = []\n",
    "labels = []\n",
    "\n",
    "for talent in talent_list:\n",
    "    path = talent[\"path\"]\n",
    "    if os.path.exists(path): \n",
    "        audio, _ = librosa.load(path, sr=sample_rate, mono=True)\n",
    "        total_duration = len(audio) / sample_rate\n",
    "        num_segments = int(total_duration)\n",
    "\n",
    "        for i in range(num_segments):\n",
    "            start_sample = int(i * sample_rate)\n",
    "            end_sample = int((i + segment_duration) * sample_rate)\n",
    "            segment = audio[start_sample:end_sample]\n",
    "\n",
    "            # Compute the MFCC for the segment\n",
    "            # mfcc = np.mean(librosa.feature.mfcc(y=segment, sr=sample_rate, n_mfcc=13)[1:], axis=1)\n",
    "\n",
    "            mfcc = get_mfcc(segment, 22050)\n",
    "            if np.isnan(mfcc).any():\n",
    "                # if mfcc array contain nan value, skip\n",
    "                continue\n",
    "            \n",
    "            mfccs.append(mfcc)\n",
    "            labels.append(talent[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9024427044037658\n"
     ]
    }
   ],
   "source": [
    "X = mfccs\n",
    "# Apply scaling for PCA\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply PCA for dimension reduction\n",
    "pca = PCA(n_components=65).fit(X_scaled)\n",
    "X_pca = pca.transform(X_scaled)\n",
    "# X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(sum(pca.explained_variance_ratio_)) \n",
    "\n",
    "import pickle\n",
    "pickle.dump(pca, open(\"pca.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y = labels\n",
    "\n",
    "# Fit an SVM model\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_pca, y, test_size = 0.2, random_state = 42, shuffle = True)\n",
    "\n",
    "clf = SVC(kernel = 'rbf', probability=True)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(accuracy_score(clf.predict(X_val), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9981447124304267\n",
      "{'C': 1, 'gamma': 0.01}\n",
      "SVC(C=1, gamma=0.01)\n"
     ]
    }
   ],
   "source": [
    "# Define the paramter grid for C from 0.001 to 10, gamma from 0.001 to 10\n",
    "C_grid = [0.001, 0.01, 0.1, 1, 10]\n",
    "gamma_grid = [0.001, 0.01, 0.1, 1, 10]\n",
    "param_grid = {'C': C_grid, 'gamma' : gamma_grid}\n",
    "\n",
    "grid = GridSearchCV(SVC(kernel='rbf'), param_grid, cv = 3, scoring = \"accuracy\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Find the best model\n",
    "print(grid.best_score_)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 0.9981447124304267\n",
    "# {'C': 1, 'gamma': 0.01}\n",
    "# SVC(C=1, gamma=0.01)\n",
    "\n",
    "# Optimal model\n",
    "clf = SVC(kernel = 'rbf', C = 1, gamma = 0.01, probability=True)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(accuracy_score(clf.predict(X_val), y_val))\n",
    "\n",
    "import pickle\n",
    "pickle.dump(clf, open(\"model-kaggle.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the entire training sets\n",
    "clf.fit(X_pca, y)\n",
    "\n",
    "clf.predict_proba(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
