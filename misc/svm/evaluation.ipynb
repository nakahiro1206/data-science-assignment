{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step: \n",
    "\n",
    "Conduct with Belmond-Shiba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# load\n",
    "with open('model-kaggle-v0.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "talent_list = [\n",
    "    {\n",
    "        \"name\": \"アンジュ・カトリーナ\",\n",
    "        \"path\": \"/content/drive/MyDrive/DataScience/chat-ange.npy\",\n",
    "        \"color\": \"#C83C35\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"リゼ・ヘルエスタ\",\n",
    "        \"path\": \"/content/drive/MyDrive/DataScience/chat-lize.npy\",\n",
    "        \"color\": \"#42FFFF\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"戌亥とこ\",\n",
    "        \"path\": \"/content/drive/MyDrive/DataScience/chat-toko.npy\",\n",
    "        \"color\": \"#92F3A4\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n9/f02ch2416_7cp5wybnwwhh7r0000gn/T/ipykernel_4216/3694596002.py:12: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(audio_filepath, sr = sample_rate)\n",
      "/opt/miniconda3/envs/general/lib/python3.12/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "audio_filepath = \"../data_collection/test-voice/sanbaka-sightseeing.mp4\"\n",
    "\n",
    "# Parameters for mel-spectrogram\n",
    "sample_rate = 22050  # Standard sample rate for Librosa. Basically equal to sample rate of the audio.\n",
    "n_mels = 128         # Number of mel bands\n",
    "n_fft = 2048         # Length of the FFT window -> ブログのやつでは173(分解能を11.5ms にするため！)\n",
    "hop_length = 256     # Number of samples between successive frames\n",
    "win_length = n_fft     # window length\n",
    "segment_duration = 2  # seconds\n",
    "\n",
    "y, sr = librosa.load(audio_filepath, sr = sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle code (https://www.kaggle.com/code/anmour/svm-using-mfcc-features)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import skew\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Generate mfcc features with mean and standard deviation\n",
    "def get_mfcc(segment, SAMPLE_RATE):\n",
    "    data = segment\n",
    "    # try:\n",
    "\n",
    "    ft1 = librosa.feature.mfcc(y = data, sr = SAMPLE_RATE, n_mfcc=30)\n",
    "    ft2 = librosa.feature.zero_crossing_rate(y = data)[0]\n",
    "    ft3 = librosa.feature.spectral_rolloff(y = data, sr = SAMPLE_RATE)[0]\n",
    "    ft4 = librosa.feature.spectral_centroid(y = data, sr = SAMPLE_RATE)[0]\n",
    "    ft5 = librosa.feature.spectral_contrast(y = data, sr = SAMPLE_RATE)[0]\n",
    "    ft6 = librosa.feature.spectral_bandwidth(y = data, sr = SAMPLE_RATE)[0]\n",
    "    ft1_trunc = np.hstack((np.mean(ft1, axis=1), np.std(ft1, axis=1), skew(ft1, axis = 1), np.max(ft1, axis = 1), np.median(ft1, axis = 1), np.min(ft1, axis = 1)))\n",
    "    ft2_trunc = np.hstack((np.mean(ft2), np.std(ft2), skew(ft2), np.max(ft2), np.median(ft2), np.min(ft2)))\n",
    "    ft3_trunc = np.hstack((np.mean(ft3), np.std(ft3), skew(ft3), np.max(ft3), np.median(ft3), np.min(ft3)))\n",
    "    ft4_trunc = np.hstack((np.mean(ft4), np.std(ft4), skew(ft4), np.max(ft4), np.median(ft4), np.min(ft4)))\n",
    "    ft5_trunc = np.hstack((np.mean(ft5), np.std(ft5), skew(ft5), np.max(ft5), np.median(ft5), np.min(ft5)))\n",
    "    ft6_trunc = np.hstack((np.mean(ft6), np.std(ft6), skew(ft6), np.max(ft6), np.median(ft6), np.max(ft6)))\n",
    "    return pd.Series(np.hstack((ft1_trunc, ft2_trunc, ft3_trunc, ft4_trunc, ft5_trunc, ft6_trunc)))\n",
    "    \n",
    "    # except:\n",
    "    #     print('bad file')\n",
    "    #     return pd.Series([0]*210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03096875 - 5.53221875: SPEAKER_01 said, ''音量調整したけど視聴者さん側にも念のため聞いてもらおうかにしましょう''\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 65 features, but SVC is expecting 210 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m pca \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpca.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     52\u001b[0m mfccs_pca \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform(mfccs_scaled)\n\u001b[0;32m---> 54\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmfccs_pca\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions)\n\u001b[1;32m     57\u001b[0m values, counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(predictions, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/general/lib/python3.12/site-packages/sklearn/multiclass.py:500\u001b[0m, in \u001b[0;36mOneVsRestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    498\u001b[0m argmaxima \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_samples, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_):\n\u001b[0;32m--> 500\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43m_predict_binary\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m     np\u001b[38;5;241m.\u001b[39mmaximum(maxima, pred, out\u001b[38;5;241m=\u001b[39mmaxima)\n\u001b[1;32m    502\u001b[0m     argmaxima[maxima \u001b[38;5;241m==\u001b[39m pred] \u001b[38;5;241m=\u001b[39m i\n",
      "File \u001b[0;32m/opt/miniconda3/envs/general/lib/python3.12/site-packages/sklearn/multiclass.py:111\u001b[0m, in \u001b[0;36m_predict_binary\u001b[0;34m(estimator, X)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m     score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mravel(\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# probabilities of the positive class\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     score \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(X)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/general/lib/python3.12/site-packages/sklearn/svm/_base.py:779\u001b[0m, in \u001b[0;36mBaseSVC.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    753\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate the decision function for the samples in X.\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \n\u001b[1;32m    755\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;124;03m    transformation of ovo decision function.\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 779\u001b[0m     dec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function_shape \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    781\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _ovr_decision_function(dec \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39mdec, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_))\n",
      "File \u001b[0;32m/opt/miniconda3/envs/general/lib/python3.12/site-packages/sklearn/svm/_base.py:529\u001b[0m, in \u001b[0;36mBaseLibSVM._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluates the decision function for the samples in X.\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;124;03m    in the model.\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# NOTE: _validate_for_predict contains check for is_fitted\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;66;03m# hence must be placed before any other attributes are used.\u001b[39;00m\n\u001b[0;32m--> 529\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_kernel(X)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/general/lib/python3.12/site-packages/sklearn/svm/_base.py:607\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    604\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[0;32m--> 607\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m    617\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/general/lib/python3.12/site-packages/sklearn/base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/miniconda3/envs/general/lib/python3.12/site-packages/sklearn/base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 65 features, but SVC is expecting 210 features as input."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "diarization = pd.read_csv(\"../pyannote/result-sightseeing.csv\")\n",
    "\n",
    "labels = [d[\"name\"] for d in talent_list]\n",
    "colors = [d[\"color\"] for d in talent_list]\n",
    "\n",
    "# Example entries\n",
    "srt_elements = [\n",
    "    # {'start': 1.0, 'end': 4.0, 'text': 'This is red text', 'color': '#FF0000'},\n",
    "    # {'start': 5.0, 'end': 7.0, 'text': 'This is green text', 'color': '#00FF00'},\n",
    "    # {'start': 6.5, 'end': 10.0, 'text': 'This is blue text overlapping', 'color': '#0000FF'},\n",
    "]\n",
    "\n",
    "for index, row in diarization.iterrows():\n",
    "    print(f\"{row[\"start\"]} - {row[\"end\"]}: {row[\"speaker\"]} said, ''{row[\"text\"]}''\")\n",
    "    start = max(int(sr * row[\"start\"]), 0)\n",
    "    end = min(int(sr * row[\"end\"]), len(y))\n",
    "    turn = y[start:end]\n",
    "\n",
    "    turn_len = len(turn)\n",
    "    # 0-2, 1-3, 2-4,,,\n",
    "    num_segments = int( turn_len / sr ) #  - segment_duration + 1\n",
    "    mfccs = []\n",
    "    for segment_index in range(num_segments):\n",
    "        segment = y[segment_index * sr : (segment_index + 1 ) * sr ]\n",
    "        # (segment_index + segment_duration) * sr ]\n",
    "\n",
    "        segment = np.concatenate((segment, segment), axis = 0)\n",
    "\n",
    "        # mfcc = np.mean(librosa.feature.mfcc(y=segment, sr=sample_rate, n_mfcc=13)[1:], axis=1)\n",
    "        mfcc = get_mfcc(segment, 22050)\n",
    "        if np.isnan(mfcc).any():\n",
    "            # if mfcc array contain nan value, skip\n",
    "            continue\n",
    "        \n",
    "        mfccs.append(mfcc)\n",
    "\n",
    "    if len(mfccs) == 0:\n",
    "        print(\"Turn's duration is under 2 sec. Unable to evaluate\")\n",
    "        continue\n",
    "\n",
    "    # change to PCA\n",
    "    # Apply scaling for PCA\n",
    "    scaler = StandardScaler()\n",
    "    mfccs_scaled = scaler.fit_transform(mfccs)\n",
    "    # Apply PCA for dimension reduction\n",
    "    import pickle\n",
    "    pca = pickle.load(open(\"pca.pkl\",'rb'))\n",
    "    mfccs_pca = pca.transform(mfccs_scaled)\n",
    "    \n",
    "    predictions = model.predict(mfccs_pca)\n",
    "    print(predictions)\n",
    "\n",
    "    values, counts = np.unique(predictions, return_counts=True)\n",
    "    print(values)\n",
    "    print(counts)\n",
    "\n",
    "    print(f\"Most Dominant: {values[np.argmax(counts)]}\")\n",
    "\n",
    "    color = colors[np.argmax(counts)]\n",
    "\n",
    "    srt_elements.append({\n",
    "        'start': row[\"start\"],\n",
    "        'end': row[\"end\"],\n",
    "        'text': row[\"text\"],\n",
    "        'color': color\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(secs: float) -> str:\n",
    "    \"\"\"Convert seconds as float to SRT time format (hh:mm:ss,ms).\"\"\"\n",
    "    hours =  int(secs) // 3600\n",
    "    minutes = (int(secs) % 3600) // 60\n",
    "    seconds = ( int(secs) % 60 ) // 1\n",
    "    milliseconds = int((secs - (int(secs) // 1)) * 1000 )\n",
    "    return f\"{str(hours).zfill(2)}:{str(minutes).zfill(2)}:{str(seconds).zfill(2)},{str(milliseconds).zfill(3)}\"\n",
    "\n",
    "def create_srt_entry(index: int, start_time: float, end_time: float, text: str, color_code: str) -> str:\n",
    "    \"\"\"Create a formatted SRT entry.\"\"\"\n",
    "    start_time_str = format_time(start_time)\n",
    "    end_time_str = format_time(end_time)\n",
    "    formatted_text = f\"[color={color_code}]{text}[/color]\"\n",
    "    return f\"{index}\\n{start_time_str} --> {end_time_str}\\n{formatted_text}\\n\"\n",
    "\n",
    "def write_srt_file(entries: list, output_file: str):\n",
    "    \"\"\"Write entries to an SRT file.\"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        for i, entry in enumerate(entries, start=1):\n",
    "            file.write(create_srt_entry(i, entry['start'], entry['end'], entry['text'], entry['color']))\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "# Write to an SRT file\n",
    "write_srt_file(srt_elements, 'sanbaka-sightseeing.srt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
